import streamlit as st
import pandas as pd
import torch
from transformers import CLIPTokenizer, CLIPModel
from api import model  # ÄÃ£ cáº¥u hÃ¬nh Gemini tá»« trÆ°á»›c

# Load CLIP model
@st.cache_resource
def load_clip_model():
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-base-patch32")
    return model, tokenizer

clip_model, tokenizer = load_clip_model()

# Load cÃ¢u há»i tá»« CSV
@st.cache_data
def load_questions(csv_path="questions.csv"):
    return pd.read_csv(csv_path)

df = load_questions()

# HÃ m tÃ­nh embedding
def get_text_embedding(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True)
    with torch.no_grad():
        outputs = clip_model.get_text_features(**inputs)
    return outputs.squeeze()

# Streamlit UI
st.title("ğŸ” á»¨ng dá»¥ng Trá»£ lÃ½ cÃ¢u há»i (CLIP + Gemini)")
st.write("Nháº­p má»™t cÃ¢u há»i báº¥t ká»³. Há»‡ thá»‘ng sáº½ tÃ¬m cÃ¢u gáº§n giá»‘ng nháº¥t trong dá»¯ liá»‡u vÃ  Ä‘Æ°a ra Ä‘Ã¡p Ã¡n tá»‘i Æ°u.")

user_question = st.text_area("âœï¸ Nháº­p cÃ¢u há»i", "")

if st.button("TÃ¬m vÃ  Tá»‘i Æ°u cÃ¢u tráº£ lá»i") and user_question.strip():
    with st.spinner("ğŸ” Äang tÃ¬m kiáº¿m vÃ  xá»­ lÃ½..."):
        user_embedding = get_text_embedding(user_question)

        similarities = []
        for q in df["CÃ¢u há»i"]:
            q_embed = get_text_embedding(q)
            sim = torch.nn.functional.cosine_similarity(user_embedding, q_embed, dim=0).item()
            similarities.append(sim)

        best_index = similarities.index(max(similarities))
        matched_row = df.iloc[best_index]

        best_question = matched_row["CÃ¢u há»i"]
        correct_answer = matched_row["ÄÃ¡p Ã¡n Ä‘Ãºng"]
        options = matched_row.get("CÃ¡c lá»±a chá»n", None)
        image = matched_row.get("áº¢nh minh há»a", None)

        st.subheader("âœ… CÃ¢u há»i tÆ°Æ¡ng tá»± nháº¥t trong dá»¯ liá»‡u:")
        st.write(best_question)

        if options:
            st.subheader("ğŸ“‹ CÃ¡c lá»±a chá»n:")
            for opt in str(options).split("\n"):
                st.markdown(f"- {opt.strip()}")

        st.subheader("âœ”ï¸ ÄÃ¡p Ã¡n Ä‘Ãºng:")
        st.markdown(f"**{correct_answer}**")

        if isinstance(image, str) and image.strip():
            try:
                st.image(image.strip(), caption="áº¢nh minh há»a", use_column_width=True)
            except:
                st.warning("âš ï¸ KhÃ´ng thá»ƒ táº£i áº£nh minh há»a.")

        # Tá»‘i Æ°u vá»›i Gemini
        gemini_prompt = f"""CÃ¢u há»i ngÆ°á»i dÃ¹ng: {user_question}
CÃ¢u há»i tÆ°Æ¡ng tá»± trong dá»¯ liá»‡u: {best_question}
ÄÃ¡p Ã¡n Ä‘Ãºng: {correct_answer}
HÃ£y Ä‘Æ°a ra má»™t cÃ¢u tráº£ lá»i ngáº¯n gá»n, chÃ­nh xÃ¡c vÃ  dá»… hiá»ƒu."""

        gemini_response = model.generate_content(gemini_prompt)
        st.subheader("ğŸ¤– Tráº£ lá»i tá»« Gemini:")
        st.write(gemini_response.text)
